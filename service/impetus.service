[Unit]
Description=Impetus LLM Server - High-performance local LLM server for Apple Silicon
Documentation=https://github.com/GerdsenAI/Impetus-LLM-Server
After=network.target

[Service]
Type=notify
User=%i
Group=%i
WorkingDirectory=/home/%i/impetus-llm-server/gerdsen_ai_server
Environment="PATH=/home/%i/impetus-llm-server/venv/bin:/usr/local/bin:/usr/bin:/bin"
Environment="PYTHONUNBUFFERED=1"
Environment="IMPETUS_ENVIRONMENT=production"
ExecStart=/home/%i/impetus-llm-server/venv/bin/gunicorn \
    --config /home/%i/impetus-llm-server/gerdsen_ai_server/gunicorn_config.py \
    --worker-class eventlet \
    wsgi:application
Restart=always
RestartSec=10
StandardOutput=journal
StandardError=journal
SyslogIdentifier=impetus-llm-server

# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=read-only
ReadWritePaths=/home/%i/impetus-llm-server/models
ReadWritePaths=/var/log/impetus

# Resource limits
# Memory and CPU limits should be adjusted based on your hardware
# MemoryLimit=16G
# CPUQuota=400%
LimitNOFILE=65536
LimitNPROC=4096

[Install]
WantedBy=multi-user.target