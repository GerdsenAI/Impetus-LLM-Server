# Impetus LLM Server Configuration
# Copy this file to .env and customize as needed

# Server Configuration
IMPETUS_HOST=0.0.0.0
IMPETUS_PORT=8080
IMPETUS_DEBUG=false
IMPETUS_API_KEY=your-secret-api-key-here

# Environment
IMPETUS_ENV=development

# Model Configuration
IMPETUS_DEFAULT_MODEL=mlx-community/Mistral-7B-Instruct-v0.3-4bit
IMPETUS_MAX_LOADED_MODELS=3
IMPETUS_LOAD_IN_4BIT=true

# Inference Settings
IMPETUS_MAX_TOKENS=2048
IMPETUS_TEMPERATURE=0.7
IMPETUS_TOP_P=0.95
IMPETUS_STREAM_BY_DEFAULT=true

# Hardware Settings
IMPETUS_PERFORMANCE_MODE=balanced
IMPETUS_ENABLE_THERMAL_MANAGEMENT=true
IMPETUS_MAX_CPU_PERCENT=80.0
IMPETUS_MAX_MEMORY_PERCENT=75.0

# Logging
IMPETUS_LOG_LEVEL=INFO
IMPETUS_LOG_FILE=/tmp/impetus.log