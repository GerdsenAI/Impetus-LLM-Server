# Impetus-LLM-Server Environment Configuration Example
# Copy this file to .env and adjust values as needed

# Server settings
PORT=8080
DEBUG=False
LOG_LEVEL=INFO

# Model settings
MODEL_CACHE_DIR=./models
DEFAULT_MODEL=phi-3-mini-4k-instruct-q4.gguf
MAX_CONTEXT_LENGTH=4096
MAX_BATCH_SIZE=8

# Performance settings (0 = auto-detect)
NUM_THREADS=0
MAX_MEMORY_GB=0

# API settings
API_KEY=sk-your-secure-api-key-here
ENABLE_CORS=True
RATE_LIMIT_PER_MINUTE=100

# Hardware optimization (Apple Silicon)
ENABLE_METAL=True
ENABLE_NEURAL_ENGINE=True
AUTO_OPTIMIZE=True
THERMAL_THROTTLE=True

# Model downloading
HF_TOKEN=  # Optional: Hugging Face token for private models
MODEL_DOWNLOAD_TIMEOUT=3600

# Monitoring
ENABLE_METRICS=True
METRICS_PORT=9090

# Security
ENABLE_AUTH=False  # Set to True for production
ALLOWED_ORIGINS=http://localhost:*,http://127.0.0.1:*